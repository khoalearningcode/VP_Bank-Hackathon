import base64
import os
import re
import time
import sys
import cv2
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
import easyocr
import cv2
import numpy as np
from PIL import Image
import pandas as pd
import torch
import torch.nn.functional as F
from transformers import TrOCRProcessor, VisionEncoderDecoderModel, pipeline
from difflib import SequenceMatcher
from io import BytesIO
from paddleocr import PaddleOCR
import pytesseract
from PIL import Image, ImageDraw, ImageFont
from mmocr.apis import TextRecInferencer
import mmcv
import mmengine
import traceback
import concurrent.futures
import urllib.request
from pdf2image import convert_from_bytes
import fasttext
import json
import uuid
import hashlib
import datetime
import uuid
import hashlib
from typing import Dict, Any
import uuid

if not hasattr(np, 'sctypes'):
    np.sctypes = {
        'int': [np.int8, np.int16, np.int32, np.int64],
        'uint': [np.uint8, np.uint16, np.uint32, np.uint64],
        'float': [np.float16, np.float32, np.float64],
        'complex': [np.complex64, np.complex128]
    }

url = "https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz"
urllib.request.urlretrieve(url, "lid.176.ftz")
model_lang_detect = fasttext.load_model("lid.176.ftz")
print("T·∫£i th√†nh c√¥ng lid.176.ftz")

print("mmcv version:", mmcv.__version__)
print("mmengine version:", mmengine.__version__)

print("MMOCR inference ready!")

trocr_processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-printed")
trocr_model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-printed")

def load_text_detection_model():
    """Load PaddleOCR (DBNet/DBNet++) for detection only."""
    ocr_detector = PaddleOCR(
        use_doc_orientation_classify=False,
        use_doc_unwarping=False,
        use_textline_orientation=False)
   
    return ocr_detector
text_detector = load_text_detection_model()

def fasttext_detect_lang(text):
    """
    Detect language using FastText, return lang + confidence
    """
    if not text or not text.strip():
        return "unknown", 0.0

    text_norm = text.strip()

    try:
        labels, probs = model_lang_detect.predict(text_norm)
        lang = labels[0].replace("__label__", "")
        prob = probs[0]
    except Exception:
        lang, prob = "unknown", 0.0

    # N·∫øu confidence cao ‚Üí tin t∆∞·ªüng k·∫øt qu·∫£
    if prob >= 0.5:
        return lang, prob

    # --- Fallback khi FastText kh√¥ng ch·∫Øc ch·∫Øn ---
    clean_text = re.sub(r'[^\w\s]', '', text_norm, flags=re.UNICODE).strip()
    if not clean_text:
        return "unknown", 0.0

    # Ki·ªÉm tra ti·∫øng Vi·ªát
    if re.search(r'[√†√°·∫£√£·∫°ƒÉ·∫±·∫Ø·∫≥·∫µ·∫∑√¢·∫ß·∫•·∫©·∫´·∫≠ƒë√®√©·∫ª·∫Ω·∫π√™·ªÅ·∫ø·ªÉ·ªÖ·ªá√¨√≠·ªâƒ©·ªã√≤√≥·ªè√µ·ªç√¥·ªì·ªë·ªï·ªó·ªô∆°·ªù·ªõ·ªü·ª°·ª£√π√∫·ªß≈©·ª•∆∞·ª´·ª©·ª≠·ªØ·ª±·ª≥√Ω·ª∑·ªπ·ªµ]', clean_text, re.IGNORECASE):
        return "vi", 0.8  # gi·∫£ ƒë·ªãnh confidence trung b√¨nh 0.8

    # N·∫øu ch·ªâ ch·ª©a k√Ω t·ª± Latin c∆° b·∫£n (kh√¥ng d·∫•u) ‚Üí coi l√† ti·∫øng Anh
    if re.fullmatch(r'[a-zA-Z0-9\s]+', clean_text):
        return "en", 0.8

    return "unknown", 0.0

def detect_text_regions(image):
    """Detect text boxes and recognition results using PaddleOCR predict()."""
    import tempfile
    tmp_path = tempfile.mktemp(suffix=".jpg")
    cv2.imwrite(tmp_path, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))

    start_time = time.time()
    results = text_detector.predict(tmp_path)
    runtime_total = round(time.time() - start_time, 3)

    df_records = []
    boxes = []
    box_times = []

    if not results:
        print("Kh√¥ng ph√°t hi·ªán v√πng ch·ªØ n√†o.")
        return boxes, pd.DataFrame()

    for res in results:
        # M·ªói ph·∫ßn t·ª≠ c√≥ th·ªÉ l√† object ho·∫∑c dict
        if hasattr(res, "res"):
            res_data = res.res
        elif isinstance(res, dict):
            res_data = res
        elif hasattr(res, "__dict__"):
            res_data = res.__dict__
        else:
            print("Kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c ki·ªÉu k·∫øt qu·∫£:", type(res))
            continue

        # Debug th·ª≠
        print("üîë Keys trong res_data:", list(res_data.keys()))

        dt_polys = res_data.get("dt_polys")
        dt_scores = res_data.get("dt_scores", [])
        rec_texts = res_data.get("rec_texts", [])
        rec_scores = res_data.get("rec_scores", [])

        if dt_polys is None:
            print("Kh√¥ng c√≥ dt_polys trong res_data.")
            continue

        for i, poly in enumerate(dt_polys):
            try:
                box_start = time.time()
                points = np.array(poly, dtype=np.int32)
                x_min = int(np.min(points[:, 0]))
                y_min = int(np.min(points[:, 1]))
                x_max = int(np.max(points[:, 0]))
                y_max = int(np.max(points[:, 1]))
                score = float(dt_scores[i]) if i < len(dt_scores) else 1.0

                # N·∫øu c√≥ nh·∫≠n d·∫°ng ch·ªØ
                text = rec_texts[i] if i < len(rec_texts) else ""
                rec_conf = float(rec_scores[i]) if i < len(rec_scores) else score

                # Ph√°t hi·ªán ng√¥n ng·ªØ n·∫øu c√≥ text
                if text.strip():
                    lang, lang_conf = fasttext_detect_lang(text)
                else:
                    lang, lang_conf = "unknown", 0.0
                
                box_runtime = round(time.time() - box_start, 4)

                boxes.append({
                    "bbox": (x_min, y_min, x_max, y_max),
                    "score": rec_conf,
                    "runtime": box_runtime
                })

                df_records.append({
                    "doc_preprocessor_res": {
                        "angle": 0,
                        "input_path": None,
                        "model_settings": {
                            "use_doc_orientation_classify": False,
                            "use_doc_unwarping": False
                        },
                        "page_index": None
                    },
                    "dt_polys": [poly],
                    "input_path": tmp_path,
                    "model_settings": {
                        "use_doc_preprocessor": False,
                        "use_textline_orientation": False
                    },
                    "page_index": None,
                    "rec_boxes": [list(map(int, [x_min, y_min, x_max, y_max]))],
                    "rec_polys": [poly],
                    "rec_scores": [rec_conf],
                    "rec_texts": [text],
                    "return_word_box": False,
                    "text_det_params": {
                        "box_thresh": 0.5,
                        "limit_side_len": 960,
                        "limit_type": "max",
                        "max_side_limit": 960,
                        "thresh": 0.3,
                        "unclip_ratio": 2.0
                    },
                    "text_rec_score_thresh": 0,
                    "text_type": "general",
                    "textline_orientation_angles": [],
                    "runtime": [box_runtime],
                    "lang": lang,
                    "lang_conf": float(lang_conf)
                })

            except Exception as e:
                print(f"‚ùå L·ªói khi x·ª≠ l√Ω polygon: {e}")
                continue

    df_paddle = pd.DataFrame(df_records)
    print(f"‚úÖ PaddleOCR ph√°t hi·ªán {len(boxes)} v√πng ch·ªØ, th·ªùi gian: {runtime_total:.3f}s")
    return boxes, df_paddle

def draw_unicode_text(img, text, pos, color=(0, 255, 0), font_path="Roboto-Black.ttf", font_size=18):
    """
    V·∫Ω ch·ªØ Unicode (ti·∫øng Vi·ªát c√≥ d·∫•u) l√™n ·∫£nh OpenCV b·∫±ng Pillow.
    """
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    try:
        font = ImageFont.truetype(font_path, font_size)
    except:
        font = ImageFont.load_default()
    draw.text(pos, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

def extract_text(image):
    annotated = image.copy()
    ocr_texts, raw_text_list = [], []

    # --- Load c√°c m√¥ h√¨nh OCR ---
    reader = easyocr.Reader(['vi', 'en'], gpu=False)
    rec_inferencer = TextRecInferencer(model='sar')
    
    def timed_run(func, crop, name):
        start = time.time()
        result = func(crop)
        end = time.time()
        result["runtime"] = round(end - start, 3)
        result["model"] = name
        return result

    # ========== H√ÄM OCR ==========
    def run_ocr_tesseract(crop):
        try:
            # gray = preprocess_for_ocr(crop)
            config = '--oem 3 --psm 6 -l vie+eng'
            text = pytesseract.image_to_string(crop, config=config).strip()
            text = re.sub(r'\s+', ' ', text)
            conf = 0.5 if text else 0.0
            lang, lang_conf = fasttext_detect_lang(text) if text else ("unknown", 0.0)
            return {"text": text, "conf": conf, "lang": lang, "lang_conf": lang_conf}
        except Exception as e:
            print(f"‚ùå L·ªói Tesseract: {e}")
            return {"text": "", "conf": 0.0, "lang": "unknown", "lang_conf": 0.0}

    def run_ocr_easyocr(crop):
        try:
            # gray = preprocess_for_ocr(crop)
            results = reader.readtext(crop)
            if not results:
                return {"text": "", "conf": 0.0, "lang": "unknown", "lang_conf": 0.0}
            _, text, conf = max(results, key=lambda x: x[2])
            lang, lang_conf = fasttext_detect_lang(text) if text else ("unknown", 0.0)
            return {"text": text, "conf": conf, "lang": lang, "lang_conf": lang_conf}
        except Exception as e:
            print(f"‚ùå L·ªói EasyOCR: {e}")
            return {"text": "", "conf": 0.0, "lang": "unknown", "lang_conf": 0.0}

    def run_ocr_mmocr(crop):
        try:
            # crop_rgb = cv2.cvtColor(crop, cv2.COLOR_BGR2RGB)
            result = rec_inferencer(crop)
            preds = result['predictions'][0]
            text, conf = preds['text'], preds['scores']
            lang, lang_conf = fasttext_detect_lang(text) if text else ("unknown", 0.0)
            return {"text": text, "conf": float(conf), "lang": lang, "lang_conf": lang_conf}
        except Exception as e:
            print(f"‚ùå L·ªói MMOCR: {type(e).__name__} - {e}")
            traceback.print_exc()
            return {"text": "", "conf": 0.0, "lang": "unknown", "lang_conf": 0.0}

    def run_ocr_trocr(crop):
        try:
            # image_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))
            pixel_values = trocr_processor(images=crop, return_tensors="pt").pixel_values
            with torch.no_grad():
                outputs = trocr_model.generate(
                    pixel_values,
                    output_scores=True,
                    return_dict_in_generate=True
                )
            text = trocr_processor.batch_decode(outputs.sequences, skip_special_tokens=True)[0].strip()
            conf = 0.0
            if hasattr(outputs, "scores") and len(outputs.scores) > 0:
                probs = []
                sequence = outputs.sequences[0][1:]
                for score_tensor, token_id in zip(outputs.scores, sequence):
                    token_id = int(token_id)
                    probs.append(F.softmax(score_tensor.squeeze(0), dim=-1)[token_id].item())
                if probs:
                    conf = float(np.mean(probs))
            lang, lang_conf = fasttext_detect_lang(text) if text else ("unknown", 0.0)
            return {"text": text, "conf": conf, "lang": lang, "lang_conf": lang_conf}
        except Exception as e:
            print(f"‚ùå L·ªói TrOCR: {type(e).__name__} - {e}")
            traceback.print_exc()
            return {"text": "", "conf": 0.0, "lang": "unknown", "lang_conf": 0.0}

    # ========== C√îNG C·ª§ H·ªñ TR·ª¢ ==========
    def clean_text(t):
        t = re.sub(r'[^0-9A-Za-z√Ä-·ªπ\s.,:/%()+=-]', '', t)
        t = re.sub(r'\s+', ' ', t).strip()
        return t
    
    def has_good_spacing(text):
        return bool(re.search(r'[A-Za-z√Ä-·ªπ]+\s+[A-Za-z√Ä-·ªπ]+', text))

    def normalize_case(text):
        if not text.strip():
            return text

        letters = re.findall(r'[A-Za-z√Ä-·ªπ]', text)
        if not letters:
            return text  

        upper_count = sum(1 for c in letters if c.isupper())
        lower_count = len(letters) - upper_count

        if upper_count >= 0.7 * len(letters):
            return text.upper()

        elif lower_count >= 0.7 * len(letters):
            return text.lower()
        else:
            return text
    
    def text_similarity(a, b):
        a_clean = re.sub(r'[^A-Za-z√Ä-·ªπ0-9]', '', a.lower())
        b_clean = re.sub(r'[^A-Za-z√Ä-·ªπ0-9]', '', b.lower())
        ratio = SequenceMatcher(None, a_clean, b_clean).ratio()
        return ratio * (1 - abs(len(a_clean) - len(b_clean)) / max(len(a_clean), len(b_clean), 1))
 
    def choose_best_text(results):
        """
        Ch·ªçn text t·ªët nh·∫•t t·ª´ nhi·ªÅu m√¥ h√¨nh OCR,
        ∆Øu ti√™n ti·∫øng Vi·ªát v√† lang_conf cao.
        """
        texts = [r for r in results.values() if r.get("text")]

        if not texts:
            return "(r·ªóng)", 0.0, "unknown"

        # L√†m s·∫°ch v√† chu·∫©n h√≥a ch·ªØ
        for r in texts:
            r["text"] = normalize_case(clean_text(r["text"]))
            if not r.get("lang") or r["lang"] == "unknown":
                try:
                    lang, lang_conf = fasttext_detect_lang(r["text"])
                    r["lang"], r["lang_conf"] = lang, lang_conf
                except:
                    r["lang"], r["lang_conf"] = "unknown", 0.0

        # --- ∆Øu ti√™n text ti·∫øng Vi·ªát ---
        vi_texts = [t for t in texts if t["lang"] == "vi" and t["lang_conf"] >= 0.6]

        if vi_texts:
            candidates = vi_texts
            print(f"üü© ∆Øu ti√™n {len(candidates)} text ti·∫øng Vi·ªát c√≥ lang_conf ‚â• 0.6")
        else:
            # N·∫øu kh√¥ng c√≥ ti·∫øng Vi·ªát ƒë√°ng tin, ch·ªçn ng√¥n ng·ªØ c√≥ lang_conf cao nh·∫•t
            max_lang_conf = max(t["lang_conf"] for t in texts)
            candidates = [t for t in texts if t["lang_conf"] >= max_lang_conf * 0.9]
            print(f"‚ö†Ô∏è Kh√¥ng c√≥ ti·∫øng Vi·ªát r√µ r√†ng ‚Üí fallback top {len(candidates)} ng√¥n ng·ªØ kh√°c")

        has_space = [t for t in candidates if " " in t["text"]]
        if has_space:
            candidates = has_space
            print(f"üü¶ ∆Øu ti√™n {len(candidates)} text c√≥ d·∫•u c√°ch r√µ r√†ng")

        # --- ∆Øu ti√™n th√™m theo confidence ---
        max_conf = max(t["conf"] for t in candidates)
        top_conf = [t for t in candidates if t["conf"] >= max_conf * 0.9]

        # --- ∆Øu ti√™n text c√≥ spacing h·ª£p l√Ω ---
        spaced = [t for t in top_conf if has_good_spacing(t["text"])]
        pool = spaced if spaced else top_conf

        # --- ∆Øu ti√™n text d√†i h∆°n (c√≥ nhi·ªÅu t·ª´ h∆°n) ---
        pool = sorted(pool, key=lambda t: (len(t["text"].split()), t["conf"]), reverse=True)

        best = pool[0]
        print(f"‚úÖ Ch·ªçn: {best['text']} ({best['conf']:.2f}) lang={best['lang']} lang_conf={best['lang_conf']:.2f}")

        return best["text"], float(best["conf"]), best["lang"]

    # ========== PH√ÅT HI·ªÜN V√ôNG CH·ªÆ ==========
    boxes, df_paddle  = detect_text_regions(image)
    if not boxes:
        print(" Kh√¥ng ph√°t hi·ªán v√πng ch·ªØ, fallback to√†n ·∫£nh.")
        boxes = [(0, 0, image.shape[1], image.shape[0])]

    # ========== CH·∫†Y OCR TR√äN T·ª™NG V√ôNG ==========
    for idx, box in enumerate(boxes, start=1):
        try:
            (x_min, y_min, x_max, y_max) = box if not isinstance(box, dict) else box["bbox"]
            pad = 0
            x_min, y_min = max(0, x_min - pad), max(0, y_min - pad)
            x_max, y_max = min(image.shape[1], x_max + pad), min(image.shape[0], y_max + pad)
            crop = image[y_min:y_max, x_min:x_max]

            rec_text, rec_conf, rec_lang, rec_lang_conf = "", 0.0, "unknown", 0.0
            if not df_paddle.empty:
                # T√¨m h√†ng c√≥ rec_boxes tr√πng bbox hi·ªán t·∫°i
                match = df_paddle[
                    df_paddle["rec_boxes"].apply(
                        lambda b: list(map(int, [x_min, y_min, x_max, y_max])) in b
                    )
                ]
                if not match.empty:
                    rec_text = match.iloc[0]["rec_texts"][0]
                    rec_conf = float(match.iloc[0]["rec_scores"][0])
                    rec_lang = match.iloc[0].get("lang", "unknown")
                    rec_lang_conf = float(match.iloc[0].get("lang_conf", 0.0))

            with concurrent.futures.ThreadPoolExecutor() as executor:
                futures = {
                    "tesseract": executor.submit(timed_run, run_ocr_tesseract, crop, "tesseract"),
                    "easyocr": executor.submit(timed_run, run_ocr_easyocr, crop, "easyocr"),
                    "mmocr": executor.submit(timed_run, run_ocr_mmocr, crop, "mmocr"),
                    "trocr": executor.submit(timed_run, run_ocr_trocr, crop, "trocr")
                }
                results = {k: f.result() for k, f in futures.items()}

            results["paddleocr"] = {
                "text": rec_text,
                "conf": rec_conf,
                "lang": rec_lang,
                "lang_conf": rec_lang_conf,
                "runtime": 0.0,
                "model": "paddleocr"
            }
            # ---- Ch·ªçn text t·ªët nh·∫•t ----
            best_text, best_conf, best_lang = choose_best_text(results)
            log_entry = {
                
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "region_index": idx,
                "bbox": [x_min, y_min, x_max, y_max],
                "models": results,
                "best_text": best_text,
                "best_conf": best_conf,
                "best_lang": best_lang
            }
            # append_log(log_entry)
            best_text, best_conf, best_lang = choose_best_text(results)
            corr = corrector(best_text, max_length=MAX_LENGTH)
            best_text = corr[0]["generated_text"]
            best_text = map_vietnamese_to_schema(best_text)

            # color = (0, 255, 0) if best_text != "(r·ªóng)" else (0, 200, 255)
            # annotated = draw_unicode_text(annotated, best_text, (x_min, max(0, y_min - 18)), color)
            # cv2.rectangle(annotated, (x_min, y_min), (x_max, y_max), color, 2)

            ocr_texts.append({
                "bbox": {"x": x_min, "y": y_min, "width": x_max - x_min, "height": y_max - y_min},
                "models": results,
                "final_text": best_text,
                "final_conf": best_conf,
                "lang": best_lang
            })
            raw_text_list.append(best_text)

            print(f"\nV√πng {idx}:")
            for name, r in results.items():
                print(f"  {name:<12} ‚Üí {r['text']} ({r['conf']:.2f}) [lang={r.get('lang','unknown')}, lang_conf={r.get('lang_conf',0.0):.2f}]")

            print(f" Ch·ªçn: {best_text} ({best_conf:.2f}) [lang={best_lang}]")

        except Exception as e:
            print(f" L·ªói x·ª≠ l√Ω v√πng {idx}: {e}")
            traceback.print_exc()

    print(f"\nHo√†n t·∫•t OCR: {len(ocr_texts)} v√πng.")
    # return " ".join(raw_text_list), ocr_texts, annotated
    return " ".join(map(str, raw_text_list)), ocr_texts

MAX_LENGTH = 512
corrector = pipeline("text2text-generation", model="bmd1905/vietnamese-correction")

COMPANY_TYPE_MAPPING: Dict[str, str] = {
    # T·ª´ ƒë·∫ßy ƒë·ªß
    "C√îNG TY": "CT",
    "C√îNGTY": "CT",
    "TR√ÅCH NHI·ªÜM H·ªÆU H·∫†N": "TNHH",
    "M·ªòT TH√ÄNH VI√äN": "MTV",
    "HAI TH√ÄNH VI√äN": "HTV",
    "C·ªî PH·∫¶N": "CP",
    "PH√ÅT TRI·ªÇN": "PT",
    "TH∆Ø∆†NG M·∫†I": "TM",
    "D·ªäCH V·ª§": "DV",
    "ƒê·∫¶U T∆Ø": "ƒêT",
    # T·ª´ vi·∫øt t·∫Øt
    "CT": "CT",
    "TNHH": "TNHH",
    "MTV": "MTV",
    "HTV": "HTV",
    "CP": "CP",
    "PT": "PT",
    "TM": "TM",
    "DV": "DV",
    "ƒêT": "ƒêT",
    "TV": "TV", # T∆∞ V·∫•n (gi·∫£ ƒë·ªãnh)
    "XD": "XD", # X√¢y D·ª±ng (gi·∫£ ƒë·ªãnh)
    "VT": "VT", # V·∫≠n T·∫£i (gi·∫£ ƒë·ªãnh)
    "GP": "GP", # Gi·∫£i Ph√°p (gi·∫£ ƒë·ªãnh)
    "JSC": "JSC", # Joint Stock Company
    "CO LTD": "Co LTD", # Company Limited
    "HKD": "HKD" # H·ªô Kinh Doanh
}

ID_TYPE_MAPPING: Dict[str, str] = {
    "CƒÇN C∆Ø·ªöC C√îNG D√ÇN": "CCCD",
    "CCCD": "CCCD",
    "CH·ª®NG MINH NH√ÇN D√ÇN": "CMND",
    "CMND": "CMND",
    "H·ªò CHI·∫æU": "Passport",
    "H·ªå CHI·∫æU": "Passport", 
    "PASSPORT": "Passport",
}

SCHEMA_PATTERNS = {
    "company_name": [
        r"c√¥ng\s*ty",
        r"doanh\s*nghi·ªáp",
        r"t·∫≠p\s*ƒëo√†n",
    ],
    "company_type": [
        r"tr√°ch\s*nhi·ªám\s*h·ªØu\s*h·∫°n|t\.?n\.?h\.?h",
        r"c·ªï\s*ph·∫ßn|c\.?p",
        r"m·ªôt\s*th√†nh\s*vi√™n|m\.?t\.?v",
        r"h·ª£p\s*t√°c|h\.?t\.?x",
    ],
    "personal_info.id_type": [
        r"cccd|cmnd|cƒÉn\s*c∆∞·ªõc",
        r"h·ªô\s*chi·∫øu|passport",
    ],
    "personal_info.id_number": [
        r"\b\d{9,12}\b",
    ],
    "personal_info.full_name": [
        r"(√¥ng|b√†)\s+[A-Z√Ä√Å·∫¢√É·∫†√ÇƒÇƒê√ä√î∆†∆Ø][\w\s]+",
    ],
    "appointment_date": [
        r"\d{1,2}/\d{1,2}/\d{4}",
        r"ng√†y\s+\d{1,2}\s+th√°ng\s+\d{1,2}\s+nƒÉm\s+\d{4}",
    ],
    "signing_authority": [
        r"gi√°m\s*ƒë·ªëc|t·ªïng\s*gi√°m\s*ƒë·ªëc|ch·ªß\s*t·ªãch|ph√≥\s*gi√°m\s*ƒë·ªëc",
    ],
}

def map_vietnamese_to_schema(best_text: str) -> Dict[str, Any]:
    # N·∫øu ƒë·∫ßu v√†o l√† list => join l·∫°i
    if isinstance(best_text, list):
        best_text = " ".join(best_text)

    text = best_text.upper().replace("\n", " ")

    normalized = {
        "company_name": "",
        "company_type": "",
        "personal_info": {"id_type": "", "id_number": "", "full_name": ""},
        "appointment_date": {"day": 0, "month": 0, "year": 0},
        "signing_authority": "",
        "signing_person": {"full_name": "", "title": "", "is_authorized": False}
    }

    # --- 1Ô∏è‚É£ Company Name & Type ---
    # T√¨m c√¥ng ty + lo·∫°i h√¨nh
    m = re.search(r"C√îNG\s*TY\s*(TR√ÅCH\s*NHI·ªÜM\s*H·ªÆU\s*H·∫†N|C·ªî\s*PH·∫¶N|M·ªòT\s*TH√ÄNH\s*VI√äN|TNHH|CP|MTV)?\s*([A-Z√Ä-·ª∏0-9\s]+)", text)
    if m:
        company_type_raw = m.group(1) or ""
        company_name_raw = m.group(2).strip(" .,:;-")

        # G√°n lo·∫°i h√¨nh
        for k, v in COMPANY_TYPE_MAPPING.items():
            if k in company_type_raw:
                normalized["company_type"] = v
                break

        normalized["company_name"] = f"C√îNG TY {company_type_raw} {company_name_raw}".strip()

    # --- 2Ô∏è‚É£ ID Type + Number ---
    id_match = re.search(r"\b(\d{6,15})\b", text)
    if id_match:
        id_number = id_match.group(1)
        normalized["personal_info"]["id_number"] = id_number
        # 12 s·ªë ‚Üí CCCD, 9 s·ªë ‚Üí CMND, c√≤n l·∫°i ‚Üí Passport
        if len(id_number) == 12:
            normalized["personal_info"]["id_type"] = "CCCD"
        elif len(id_number) == 9:
            normalized["personal_info"]["id_type"] = "CMND"
        else:
            normalized["personal_info"]["id_type"] = "Passport"

    # --- 3Ô∏è‚É£ Full Name ---
    # --- 3Ô∏è‚É£ Full Name (ƒê√£ S·ª≠a) ---
    m = re.search(
        r"(√îNG/B√Ä|√¥ng/b√†|√îNG|B√Ä|√îNG\-B√Ä|√îng|B√†)\s*[:\-]?\s*([A-Z√Ä-·ª∏a-z√†-·ªπ\s]{3,200})",
        text,
        flags=re.IGNORECASE
    )
    if m:
        # m.group(1) l√† danh x∆∞ng (vd: "√îNG/B√Ä")
        # m.group(2) l√† t√™n (vd: "DU∆†NG TH·ªä THANH HOA")
        
        # 1. G√°n Title (t√πy ch·ªçn)
        # title = m.group(1).upper() 
        
        # 2. L·∫•y t√™n v√† chu·∫©n h√≥a
        fullname_extracted = m.group(2).strip()
        
        # 3. G√°n t√™n ƒê√öNG v√†o full_name
        normalized["personal_info"]["full_name"] = fullname_extracted.upper()
        
        # V√≠ d·ª•: N·∫øu b·∫°n mu·ªën gi·ªØ l·∫°i danh x∆∞ng, b·∫°n n√™n d√πng m·ªôt key kh√°c
        # normalized["personal_info"]["title"] = title
    else:
        title = None
        fullname = None

    m_id = re.search(r"(CCCD|CMND|H·ªò\s*CHI·∫æU|PASSPORT)\s*[:\-]?\s*([0-9A-Z]{6,15})", text, flags=re.IGNORECASE)
    if m_id:
        id_label = m_id.group(1).upper()
        id_number = m_id.group(2)
    else:
        id_label = None
        id_number = None

    # --- 4Ô∏è‚É£ Appointment Date ---
    m = re.search(
        r"\bNG√ÄY\s+(\d{1,2})\s+TH√ÅNG\s+(\d{1,2})\s+NƒÇM\s+(\d{4})\b",
        text,
        re.IGNORECASE
    )
    if m:
        normalized["appointment_date"] = {
            "day": int(m.group(1)),
            "month": int(m.group(2)),
            "year": int(m.group(3))
        }

    # --- 5Ô∏è‚É£ Signing Authority ---
    m = re.search(r"(GI√ÅM ƒê·ªêC|T·ªîNG GI√ÅM ƒê·ªêC|CH·ª¶ T·ªäCH|PH√ì GI√ÅM ƒê·ªêC)\s*[:\-]?\s*([A-Z√Ä-·ª∏\s]+)", text)
    if m:
        title = m.group(1).title()
        person = m.group(2).strip(" ,.")
        normalized["signing_authority"] = title
        normalized["signing_person"] = {
            "full_name": person,
            "title": title,
            "is_authorized": True,
            "authorization_rule": f"Ng∆∞·ªùi k√Ω l√† {title}, c√≥ th·∫©m quy·ªÅn k√Ω vƒÉn b·∫£n h√†nh ch√≠nh."
        }

    return normalized

def pdf_to_images(content: bytes, dpi=150):
    """
    Chuy·ªÉn PDF bytes th√†nh danh s√°ch ·∫£nh numpy (m·ªói trang m·ªôt ·∫£nh)
    """
    pages = convert_from_bytes(content, dpi=dpi)
    images = [np.array(p.convert("RGB")) for p in pages]
    return images

def process_image(content: bytes, filename: str):
    ext = os.path.splitext(filename)[1].lower()
    
    if ext == ".pdf":
        print("üìÑ Ph√°t hi·ªán file PDF, chuy·ªÉn sang ·∫£nh...")
        images = pdf_to_images(content)
        results = []

        for idx, img_array in enumerate(images, start=1):
            print(f"\n--- X·ª≠ l√Ω trang {idx}/{len(images)} ---")
            text, details, annotated = extract_text(img_array)
            _, buffer = cv2.imencode(".jpg", annotated)
            annotated_b64 = base64.b64encode(buffer).decode('utf-8')
            results.append({
                "page": idx,
                "text": text,
                "details": details,
                "annotated_image": annotated_b64
            })
        return results

    elif ext in [".jpg", ".jpeg", ".png", ".bmp", ".tiff"]:
        print("üñºÔ∏è Ph√°t hi·ªán file ·∫£nh, x·ª≠ l√Ω tr·ª±c ti·∫øp...")
        img = Image.open(BytesIO(content)).convert("RGB")
        img_array = np.array(img)
        text, details, annotated = extract_text(img_array)
        _, buffer = cv2.imencode(".jpg", annotated)
        annotated_b64 = base64.b64encode(buffer).decode('utf-8')
        return [{
            "page": 1,
            "text": text,
            "details": details,
            "annotated_image": annotated_b64
        }]
    
    else:
        raise ValueError(f"Kh√¥ng h·ªó tr·ª£ ƒë·ªãnh d·∫°ng: {ext}")

def compute_image_hash(image_array):
    # ƒê·∫£m b·∫£o image_array l√† np.ndarray
    if isinstance(image_array, np.ndarray):
        # Chuy·ªÉn ·∫£nh sang bytes (encode PNG ho·∫∑c JPEG)
        success, img_bytes = cv2.imencode(".png", image_array)
        if success:
            img_bytes = img_bytes.tobytes()
        else:
            img_bytes = b""
    elif isinstance(image_array, (bytes, bytearray)):
        img_bytes = image_array
    else:
        raise TypeError(f"Kh√¥ng th·ªÉ hash ki·ªÉu d·ªØ li·ªáu: {type(image_array)}")

    return "sha256:" + hashlib.sha256(img_bytes).hexdigest()

def build_appointment_decision_json(image_array, ocr_results, user_id, doc_id, collection_id):
    collection_id = str(uuid.uuid4())
    joined_text = " ".join(
        str(t.get("final_text", "")) if isinstance(t.get("final_text"), (str, int, float)) else ""
        for t in ocr_results if isinstance(t, dict)
    )
    print("üß© Chu·ªói OCR ƒë√£ gh√©p:\n", joined_text)
    normalized = map_vietnamese_to_schema(joined_text)

    json_data = {
        "_id": collection_id,
        "public": {
            "node_data": {
                "jsonSchema": {
                    "normalized": normalized,
                    "user_id": user_id,
                    "doc_id": doc_id,
                    "created_at": datetime.datetime.now(datetime.UTC).isoformat()
                }
            }
        }
    }
    return json_data
 
def main():
    path = r"./QDBN1.pdf"
    schema_path = "./schema.json"

    if not os.path.exists(path):
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {path}")
        return

    with open(path, "rb") as f:
        content = f.read()

    ext = os.path.splitext(path)[1].lower()
    base_name = os.path.splitext(os.path.basename(path))[0]

    if ext == ".pdf":
        print("üìÑ Ph√°t hi·ªán file PDF, chuy·ªÉn sang ·∫£nh...")
        images = pdf_to_images(content)

        for idx, img in enumerate(images, start=1):
            print(f"\n--- X·ª≠ l√Ω trang {idx}/{len(images)} ---")

            # ch·∫°y OCR tr·ª±c ti·∫øp
            text, details = extract_text(cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

            # l∆∞u annotate
            # preview_path = f"annotated_page_{idx}.jpg"
            # cv2.imwrite(preview_path, cv2.cvtColor(annotated, cv2.COLOR_RGB2BGR))
            # print(f"‚úÖ ·∫¢nh ch√∫ th√≠ch OCR trang {idx} ƒë√£ l∆∞u t·∫°i: {preview_path}")

            # build JSON
            try:
                with open(schema_path, "r", encoding="utf-8") as f:
                    schema_data = json.load(f)
                    if isinstance(schema_data, list) and len(schema_data) > 0:
                        schema_data = schema_data[0]  # l·∫•y ph·∫ßn t·ª≠ ƒë·∫ßu
                    collection_id = schema_data.get("_id", "collection_appointment_decisions")
                    print(f"üì¶ ƒê·ªçc schema th√†nh c√¥ng: _id = {collection_id}")
            except Exception as e:
                print(f"‚ö†Ô∏è Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c schema.json ({e}), d√πng m·∫∑c ƒë·ªãnh 'collection_appointment_decisions'")
                collection_id = "collection_appointment_decisions"

            json_data = build_appointment_decision_json(
                image_array=np.array(img),
                ocr_results=details,
                user_id="user_001",
                doc_id=f"dec_{base_name}_page{idx}",
                collection_id=collection_id
            )

            json_path = f"appointment_decision_{base_name}_page{idx}.json"
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            print(f"‚úÖ ƒê√£ l∆∞u JSON schema trang {idx} v√†o: {json_path}")
            
    else:
        print(f"‚ö†Ô∏è Kh√¥ng h·ªó tr·ª£ ƒë·ªãnh d·∫°ng: {ext}")

if __name__ == "__main__":
    main()
